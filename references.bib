% 08.07.2016 06:00 CET ah

@article{DuchiJordan:2014:PrivacyAwareLearning,
   year = {2014},
   author = {Duchi, John C and Jordan, Michael I and Wainwright, Martin J},
   title = {Privacy aware learning},
   journal = {Journal of the ACM (JACM)},
   volume = {61},
   number = {6},
   pages = {38},
   abstract = {We study statistical risk minimization problems under a privacy model in which the data is kept confidential even from the learner. In this local privacy framework, we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures. As a consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility, as measured by convergence rate, of any statistical estimator or learning procedure.},
   doi = {10.1145/2666468}
}



@article{Zhou:2008:SurveyAnonNetwork,
   year = {2008},
   author = {Zhou, Bin and Pei, Jian and Luk, WoShun},
   title = {A brief survey on anonymization techniques for privacy preserving publishing of social network data},
   journal = {ACM Sigkdd Explorations Newsletter},
   volume = {10},
   number = {2},
   pages = {12-22},
   abstract = {Nowadays, partly driven by many Web 2.0 applications, more and more social network data has been made publicly available and analyzed in one way or another. Privacy preserving publishing of social network data becomes a more and more important concern. In this paper, we present a brief yet systematic review of the existing anonymization techniques for privacy preserving publishing of social network data. We identify the new challenges in privacy preserving publishing of social network data comparing to the extensively studied relational case, and examine the possible problem formulation in three important dimensions: privacy, background knowledge, and data utility. We survey the existing anonymization methods for privacy preservation in two categories: clustering-based approaches and graph modification approaches.}
}




@incollection{iMLExperiment,
   year = {2016},
   author = {Holzinger, A and Plass, M and Holzinger, K and Crisan, GC and Pintea, CM and Palade, V },
   title = {Towards interactive Machine Learning (iML): Applying Ant Colony Algorithms to solve the Traveling Salesman Problem with the Human-in-the-Loop approach},
   booktitle = { IFIP International Cross Domain Conference and Workshop (CD-ARES)},
   publisher = {Springer},
   address = {Heidelberg, Berlin, New York},
   pages = {in print},
   abstract = {Most Machine Learning (ML) researchers focus on automatic Machine Learning (aML) where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from the availability of "big data". However, sometimes, for example in health informatics, we are confronted not a small number of data sets or rare events, and with complex problems where aML-approaches fail or deliver unsatisfactory results. Here, interactive Machine Learning (iML) may be of help and the "human-in-the-loop" approach may be beneficial in solving computationally hard problems, where human expertise can help to reduce an exponential search space through heuristics. <br/>In this paper, experiments are discussed which help to evaluate the effectiveness of the iML-"human-in-the-loop" approach, particularly in opening the "black box", thereby enabling a human to directly and indirectly manipulating and interacting with an algorithm. For this purpose, we selected the Ant Colony Optimization (ACO) framework, and use it on the Traveling Salesman Problem (TSP) which is of high importance in solving many practical problems in health informatics, e.g. in the study of proteins.}
}




@article{Zheng:2013:reidentification,
   year = {2013},
   author = {Zheng, Wei-Shi and Gong, Shaogang and Xiang, Tao},
   title = {Reidentification by relative distance comparison},
   journal = {IEEE transactions on pattern analysis and machine intelligence},
   volume = {35},
   number = {3},
   pages = {653-668},
   abstract = {Matching people across nonoverlapping camera views at different locations and different times, known as person reidentification, is both a hard and important problem for associating behavior of people observed in a large distributed space over a prolonged period of time. Person reidentification is fundamentally challenging because of the large visual appearance changes caused by variations in view angle, lighting, background clutter, and occlusion. To address these challenges, most previous approaches aim to model and extract distinctive and reliable visual features. However, seeking an optimal and robust similarity measure that quantifies a wide range of features against realistic viewing conditions from a distance is still an open and unsolved problem for person reidentification. In this paper, we formulate person reidentification as a relative distance comparison (RDC) learning problem in order to learn the optimal similarity measure between a pair of person images. This approach avoids treating all features indiscriminately and does not assume the existence of some universally distinctive and reliable features. To that end, a novel relative distance comparison model is introduced. The model is formulated to maximize the likelihood of a pair of true matches having a relatively smaller distance than that of a wrong match pair in a soft discriminant manner. Moreover, in order to maintain the tractability of the model in large scale learning, we further develop an ensemble RDC model. Extensive experiments on three publicly available benchmarking datasets are carried out to demonstrate the clear superiority of the proposed RDC models over related popular person reidentification techniques. The results also show that the new RDC models are more robust against visual appearance changes and less susceptible to model overfitting compared to other related existing models.}
}


@article{NergizClifton:2010:Delta-Presence,
   year = {2010},
   author = {Nergiz, M. E. and Clifton, C.},
   title = {delta-Presence without Complete World Knowledge},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {22},
   number = {6},
   pages = {868-883},
   abstract = {Advances in information technology, and its use in research, are increasing both the need for anonymized data and the risks of poor anonymization. In [1], we presented a new privacy metric, delta-presence, that clearly links the quality of anonymization to the risk posed by inadequate anonymization. It was shown that existing anonymization techniques are inappropriate for situations where delta-presence is a good metric (specifically, where knowing an individual is in the database poses a privacy risk). This article addresses a practical problem with [1], extending to situations where the data anonymizer is not assumed to have complete world knowledge. The algorithms are evaluated in the context of a real-world scenario, demonstrating practical applicability of the approach.},
   keywords = {k-Anonymity, privacy, delta presence, medical databases},
   doi = {10.1109/tkde.2009.125}
}


@inproceedings{LiEtAl:2007:t-closeness,
   year = {2007},
   author = {Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh},
   title = {t-closeness: Privacy beyond k-anonymity and l-diversity},
   booktitle = {IEEE 23rd International Conference on Data Engineering, ICDE 2007},
   publisher = {IEEE},
   pages = {106-115},
   abstract = {The k-anonymity privacy requirement for publishing microdata requires that each equivalence class (i.e., a set of records that are indistinguishable from each other with respect to certain "identifying" attributes) contains at least k records. Recently, several authors have recognized that k-anonymity cannot prevent attribute disclosure. The notion of l-diversity has been proposed to address this; l-diversity requires that each equivalence class has at least l well-represented values for each sensitive attribute. In this paper we show that l-diversity has a number of limitations. In particular, it is neither necessary nor sufficient to prevent attribute disclosure. We propose a novel privacy notion called t-closeness, which requires that the distribution of a sensitive attribute in any equivalence class is close to the distribution of the attribute in the overall table (i.e., the distance between the two distributions should be no more than a threshold t). We choose to use the earth mover distance measure for our t-closeness requirement. We discuss the rationale for t-closeness and illustrate its advantages through examples and experiments.},
   doi = {10.1109/ICDE.2007.367856}
}


@article{MachanavajjhalaEtAl:2007:l-Diversity,
   year = {2007},
   author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
   title = {l-diversity: Privacy beyond k-anonymity},
   journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
   volume = {1},
   number = {1},
   pages = {1-52},
   abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called k-anonymity has gained popularity. In a k-anonymized dataset, each record is indistinguishable from at least k − 1 other records with respect to certain identifying attributes. In this article, we show using two simple attacks that a k-anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show that k-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called ℓ-diversity that can defend against such attacks. In addition to building a formal foundation for ℓ-diversity, we show in an experimental evaluation that ℓ-diversity is practical and can be implemented efficiently.},
   doi = {10.1145/1217299.1217302}
}



@article{Kieseberg:2016:Doctor-in-the-Loop,
   year = {2016},
   author = {Kieseberg, Peter and Malle, Bernd and Frühwirt, Peter and Weippl, Edgar and Holzinger, Andreas},
   title = {A tamper-proof audit and control system for the doctor in the loop},
   journal = {Brain Informatics},
   pages = {1-11},
   abstract = {The “doctor in the loop” is a new paradigm in information-driven medicine, picturing the doctor as authority inside a loop supplying an expert system with information on actual patients, treatment results, and possible additional (side-)effects, including general information in order to enhance data-driven medical science, as well as giving back treatment advice to the doctor himself. While this approach can be very beneficial for new medical approaches like P4 medicine (personal, predictive, preventive, and participatory), it also relies heavily on the authenticity of the data and thus increases the need for secure and reliable databases. In this paper, we propose a solution in order to protect the doctor in the loop against responsibility derived from manipulated data, thus enabling this new paradigm to gain acceptance in the medical community. This work is an extension of the conference paper Kieseberg et al. (Brain Informatics and Health, 2015), which includes extensions to the original concept.},
   doi = {10.1007/s40708-016-0046-2},
   url = {http://dx.doi.org/10.1007/s40708-016-0046-2}
}



@article{Holzinger:2016:iML,
   year = {2016},
   author = {Holzinger, Andreas},
   title = {Interactive Machine Learning for Health Informatics: When do we need the human-in-the-loop?},
   journal = {Springer Brain Informatics (BRIN)},
   volume = {3},
   number = {2},
   pages = {119-131},
   abstract = {Machine learning (ML) is the fastest growing field in computer science, and health informatics is amongst the greatest challenges. The goal of ML is to develop algorithms which can learn and improve over time and can be used for predictions. Most ML researchers concentrate on automatic Machine Learning (aML), where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from big data with many training sets. However, in the health domain, sometimes we are confronted with a small number of data sets or rare events, where aML-approaches suffer of insufficient training samples. Here interactive Machine Learning (iML) may be of help, having its roots in Reinforcement Learning (RL), Preference Learning (PL) and Active Learning (AL). The term iML is not yet well used, so we define it as algorithms that can interact with agents and can optimize their learning behaviour through these interactions, where the agents can also be human. This human-in-the-loop can be beneficial in solving computationally hard problems, e.g., subspace clustering, protein folding, or k-anonymization of health data, where human expertise can help to reduce an exponential search space through heuristic selection of samples. Therefore, what would otherwise be an NP-hard problem, reduces greatly in complexity through the input and the assistance of a human agent involved in the learning phase.},
   keywords = {interactive Machine learning, health informatics},
   doi = {10.1007/s40708-016-0042-6},
   url = {http://dx.doi.org/10.1007/s40708-016-0042-6}
}


@article{Sweeney:2002:k-Anonymity,
   year = {2002},
   author = {Sweeney, Latanya},
   title = {Achieving k-anonymity privacy protection using generalization and suppression},
   journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
   volume = {10},
   number = {5},
   pages = {571-588},
   abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, μ-Argus and k-Similar provide guarantees of privacy protection.},
   keywords = {Data anonymity; data privacy; re-identification; data fusion; privacy},
   doi = {10.1142/S0218488502001648 },
   url = {http://www.worldscientific.com/doi/abs/10.1142/S0218488502001648}
}

@inproceedings{Aggarwal:2005:kAnonymity,
   year = {2005},
   author = {Aggarwal, Charu C},
   title = {On k-anonymity and the curse of dimensionality},
   booktitle = {Proceedings of the 31st international conference on Very large data bases VLDB},
   pages = {901-909},
   abstract = {In recent years, the wide availability of personal data has made the problem of privacy preserving data mining an important one. A number of methods have recently been proposed for privacy preserving data mining of multidimensional data records. One of the methods for privacy preserving data mining is that of anonymization, in which a record is released only if it is indistinguishable from k other entities in the data. We note that methods such as k-anonymity are highly dependent upon spatial locality in order to effectively implement the technique in a statistically robust way. In high dimensional space the data becomes sparse, and the concept of spatial locality is no longer easy to define from an application point of view. In this paper, we view the k-anonymization problem from the perspective of inference attacks over all possible combinations of attributes. We show that when the data contains a large number of attributes which may be considered quasi-identifiers, it becomes difficult to anonymize the data without an unacceptably high amount of information loss. This is because an exponential number of combinations of dimensions can be used to make precise inference attacks, even when individual attributes are partially specified within a range. We provide an analysis of the effect of dimensionality on k-anonymity methods. We conclude that when a data set contains a large number of attributes which are open to inference attacks, we are faced with a choice of either completely suppressing most of the data or losing the desired level of anonymity. Thus, this paper shows that the curse of high dimensionality also applies to the problem of privacy preserving data mining.}
}

@article{Samarati:2001:kAnonymity,
   year = {2001},
   author = {Samarati, Pierangela},
   title = {Protecting respondents identities in microdata release},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {13},
   number = {6},
   pages = {1010-1027},
   abstract = {Today’s globally networked society places great demand on the dissemination and sharing of information. While in the past released information was mostly in tabular and statistical form, many situations call today for the release of specific data (microdata). In order to protect the anonymity of the entities (called respondents) to which information refers, data holders often remove or encrypt explicit identifiers such as names, addresses, and phone numbers. De-identifying data, however, provides no guarantee of anonymity. Released information often contains other data, such as race, birth date, sex, and ZIP code, that can be linked to publicly available information to re-identify respondents and inferring information that was not intended for disclosure. In this paper we address the problem of releasing microdata while safeguarding the anonymity of the respondents to which the data refer. The approach is based on the definition of k-anonymity . A table provides k-anonymity if attempts to link explicitly identifying information to its content map the information to at least k entities. We illustrate how k-anonymity can be provided without compromising the integrity (or truthfulness) of the information released by using generalization and suppression techniques. We introduce the concept of minimal generalization that captures the property of the release process not to distort the data more than needed to achieve k-anonymity, and present an algorithm for the computation of such a generalization. We also discuss possible preference policies to choose among different minimal generalizations. },
   keywords = {Privacy, Data Protection},
   doi = {10.1109/69.971193},
   url = {http://spdp.di.unimi.it/papers/tkde_k-anonymity.pdf}
}






%[1]
@incollection{HolzingerMalleGiuliani2014GraphExtraction,
   year = {2014},
   author = {Holzinger, Andreas and Malle, Bernd and Giuliani, Nicola},
   title = {On Graph Extraction from Image Data},
   booktitle = {Brain Informatics and Health, BIH 2014, Lecture Notes in Artificial Intelligence, LNAI 8609},
   editor = {Slezak, Dominik and Peters, James F. and Tan, Ah-Hwee and Schwabe, Lars},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {552-563},
   abstract = {Hot topics in knowledge discovery and interactive data mining from natural images include the application of topological methods and machine learning algorithms. For any such approach one needs at first a relevant and robust digital content representation from the image data. However, traditional pixel-based image analysis techniques do not effectively extract, hence represent the content. A very promising approach is to extract graphs from images, which is not an easy task. In this paper we present a novel approach for knowledge discovery by extracting graph structures from natural image data. For this purpose, we created a framework built upon modern Web technologies, utilizing HTML canvas and pure Javascript inside a Web-browser, which is a very promising engineering approach. Following a short description of some popular image classification and segmentation methodologies, we outline a specific data processing pipeline suitable for carrying out future scientific research. A demonstration of our implementation, compared to the results of a traditional watershed transformation performed in Matlab showed very promising results in both quality and runtime, despite some remaining challenges. Finally, we provide a short discussion of a few open problems and outline some of our future research routes.},
   keywords = {data preprocessing, image segmentation, image content analytics, knowledge discovery, data mining},
   doi = {10.1007/978-3-319-09891-3_50},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=868952&pCurrPk=80830}
}

%[2]
@incollection{HolzingerEtAl2014OnPCD,
   year = {2014},
   author = {Holzinger, Andreas and Malle, Bernd and Bloice, Marcus and Wiltgen, Marco and Ferri, Massimo and Stanganelli, Ignazio and Hofmann-Wellenhof, Rainer},
   title = {On the Generation of Point Cloud Data Sets: Step One in the Knowledge Discovery Process},
   booktitle = {Interactive Knowledge Discovery and Data Mining in Biomedical Informatics, Lecture Notes in Computer Science, LNCS 8401},
   editor = {Holzinger, Andreas and Jurisica, Igor},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   volume = {8401},
   pages = {57-80},
   abstract = {Computational geometry and topology are areas which have much potential for the analysis of arbitrarily high-dimensional data sets. In order to apply geometric or topological methods one must first generate a representative point cloud data set from the original data source, or at least a metric or distance function, which defines a distance between the elements of a given data set. Consequently, the first question is: How to get point cloud data sets? Or more precise: What is the optimal way of generating such data sets? The solution to these questions is not trivial. If a natural image is taken as an example, we are concerned more with the content, with the shape of the relevant data represented by this image than its mere matrix of pixels. Once a point cloud has been generated from a data source, it can be used as input for the application of graph theory and computational topology. In this paper we first describe the case for natural point clouds, i.e. where the data already are represented by points; we then provide some fundamentals of medical images, particularly dermoscopy, confocal laser scanning microscopy, and total-body photography; we describe the use of graph theoretic concepts for image analysis, give some medical background on skin cancer and concentrate on the challenges when dealing with lesion images. We discuss some relevant algorithms, including the watershed algorithm, region splitting (graph cuts), region merging (minimum spanning tree) and finally describe some open problems and future challenges [Graph-based Data Mining].},
   keywords = {data preprocessing, point cloud data sets, graphs, skin cancer, watershed algorithm, region splitting, graph cuts, region merging, mathematical morphology},
   doi = {10.1007/978-3-662-43968-5_4},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=974579&pCurrPk=83005}
}


%[3]
@incollection{PreussEtAl2014TerrainCoverage,
   year = {2014},
   author = {Preuss, Michael and Dehmer, Matthias and Pickl, Stefan and Holzinger, Andreas},
   title = {On Terrain Coverage Optimization by Using a Network Approach for universal Graph-based Data Mining and Knowledge Discovery},
   booktitle = {BIH 2014 Lecture Notes in Artificial Intelligence LNAI 8609 },
   editor = {Slezak, Dominik and Tan, Ah-Hwee and Peters, James F.  and Schwabe, Lars},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {564-573},
   abstract = {This conceptual paper discusses a graph-based approach for on-line terrain coverage, which has many important research aspects and a wide range of application possibilities, e.g in multi-agents. Such approaches can be used in different application domains, e.g. in medical image analysis. In this paper we discuss how the graphs are being generated and analyzed. In particular, the analysis is important for improving the estimation of the parameter set for the used heuristic in the field of route planning. Moreover, we describe some methods from quantitative graph theory and outline a few potential research routes.},
   keywords = {graph algorithms, multi agents, quantitative graph theory},
   doi = {10.1007/978-3-319-09891-3_51},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=974170&pCurrPk=82989}
}

%[4]
@incollection{Holzinger2014ExtravaganzaTutorial,
   year = {2014},
   author = {Holzinger, Andreas},
   title = {Extravaganza Tutorial on Hot Ideas for Interactive Knowledge Discovery and Data Mining in Biomedical Informatics},
   booktitle = {Brain Informatics and Health, BIH 2014, Lecture Notes in Artificial Intelligence, LNAI 8609},
   editor = {Slezak, Dominik and Tan, Ah-Hwee and Peters, James F and Schwabe, Lars},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {502-515},
   abstract = {Hot topics in knowledge discovery and interactive data mining from natural images include the application of topological methods and machine learning algorithms. For any such approach one needs at first a relevant and robust digital content representation from the image data. However, traditional pixel-based image analysis techniques do not effectively extract, hence represent the content. A very promising approach is to extract graphs from images, which is not an easy task. In this paper we present a novel approach for knowledge discovery by extracting graph structures from natural image data. For this purpose, we created a framework built upon modern Web technologies, utilizing HTML canvas and pure Javascript inside a Web-browser, which is a very promising engineering approach. Following a short description of some popular image classification and segmentation methodologies, we outline a specific data processing pipeline suitable for carrying out future scientific research. A demonstration of our implementation, compared to the results of a traditional watershed transformation performed in Matlab showed very promising results in both quality and runtime, despite some remaining challenges. Finally, we provide a short discussion of a few open problems and outline some of our future research routes.},
   keywords = {Knowledge Discovery, Data Mining, HCI-KDD, Graph-based Text Mining, Topological Data Mining, Entropy-based Data Mining},
   doi = {10.1007/978-3-319-09891-3_46},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=868952&pCurrPk=80830}
}

%[5]
@incollection{HolzingerOfnerDehmer2014GraphMining,
   year = {2014},
   author = {Holzinger, Andreas and Ofner, Bernhard and Dehmer, Matthias},
   title = {Multi-touch Graph-Based Interaction for Knowledge Discovery on Mobile Devices: State-of-the-Art and Future Challenges},
   booktitle = {Interactive Knowledge Discovery and Data Mining in Biomedical Informatics, Lecture Notes in Computer Science, LNCS 8401},
   editor = {Holzinger, Andreas and Jurisica, Igor},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   pages = {241-254},
   abstract = {Graph-based knowledge representation is a hot topic for some years and still has a lot of research potential, particularly in the advancement in the application of graph-theory for creating benefits in the biomedical domain. Graphs are most powerful tools to map structures within a given data set and to recognize relationships between specific data objects. Many advantages of graph-based data structures can be found in the applicability of methods from network analysis, topology and data mining (e.g. small-world phenomenon, cluster analysis). In this paper we present the state-of-the-art in graph-based approaches for multi-touch interaction on mobile devices and we highlight some open problems to stimulate further research and future developments. This is particularly important in the medical domain, as a conceptual graph analysis may provide novel insights on hidden patterns in data, hence support interactive knowledge discovery.[Graph-based Data Mining]},
   keywords = {Graph Based Interaction, Graph-based Data Mining, Interactive Node-Link Graph Visualization},
   doi = {10.1007/978-3-662-43968-5_14},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=974629&pCurrPk=83008}
}

%[6]
@article{sweeney2002k,
	title={k-anonymity: A model for protecting privacy},
	author={Sweeney, Latanya},
	journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	volume={10},
	number={05},
	pages={557--570},
	year={2002},
	publisher={World Scientific}
}

%[7]
@incollection{ciriani2007kappa,
	title={$\kappa$-anonymity},
	author={Ciriani, Valentina and di Vimercati, S De Capitani and Foresti, Sara and Samarati, Pierangela},
	booktitle={Secure data management in decentralized systems},
	pages={323--353},
	year={2007},
	publisher={Springer}
}

%[8]
@article{aggarwal2005approximation,
	title={Approximation algorithms for k-anonymity},
	author={Aggarwal, Gagan and Feder, Tomas and Kenthapadi, Krishnaram and Motwani, Rajeev and Panigrahy, Rina and Thomas, Dilys and Zhu, An},
	journal={Journal of Privacy Technology (JOPT)},
	year={2005}
}

%[9]
@article{chester2011k,
	title={k-Anonymization of Social Networks by Vertex Addition.},
	author={Chester, Sean and Kapron, Bruce and Ramesh, Ganesh and Srivastava, Gautam and Thomo, Alex and Venkatesh, S},
	journal={ADBIS (2)},
	volume={789},
	pages={107--116},
	year={2011}
}

%[10]
@inproceedings{kapron2011social,
	title={Social network anonymization via edge addition},
	author={Kapron, Bruce and Srivastava, Gautam and Venkatesh, S},
	booktitle={Advances in Social Networks Analysis and Mining (ASONAM), 2011 International Conference on},
	pages={155--162},
	year={2011},
	organization={IEEE}
}

%[11]
@incollection{campan2009data,
	title={Data and structural k-anonymity in social networks},
	author={Campan, Alina and Truta, Traian Marius},
	booktitle={Privacy, Security, and Trust in KDD},
	pages={33--54},
	year={2009},
	publisher={Springer}
}


